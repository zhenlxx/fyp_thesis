\chapter{Technologies}
\section{Parsing technologies}
\subsection{Formal Grammar}
Mathematically, formal grammar consists of:
\begin{itemize}
\item a finite set of terminal symbols.
\item a finite set of non-terminal symbols.
\item a finite set of project rules.
\item a start symbol.
\end{itemize} \cite{aho1986compilers} \cite{three_model}
From the formal grammar definition, legitimate production rules can be written as 
 \[ S \mapsto aS  \,and \, S \mapsto ab \]
In this example,we can assume that the grammar consists of two projection rules and the starting symbol is $ S $.The terminal symbols are lower letters $ \{a ,b\} $ . From this example, If we start from the either rule 1 or rule 2 ,we could derive a  grammar of $ \{ a^n b | n>1  \}$ ,which can be enumerate like $ \{aab,aaab,aaaab,\cdots \} $.



%In addition,we are able to write all the production rule from the given abstract %language, the language like



\subsection{The Hierarchy of Grammars}
Noam Chomsky has described three models of grammar \cite{three_model} and these grammar models have significantly affected the design of computer programming language.

Chomsky defines a set of rules upon the formal grammar and categorize them into different levels.

The Chomsky hierarchy consists of the 4 levels:
\begin{itemize}
\item Type-0 grammars (unrestricted grammar). It is a unrestricted grammars that include all possible grammar that are possible to recognize by Turning machine.
\item Type-1 grammars (context-sensitive grammar).if all rules are of the form $  \alpha A \beta \rightarrow \alpha \gamma \beta$ where $ \alpha \,  \beta \, \gamma $ are terminal symbols and $ A $ is non-terminal symbol.
\item Type-2 grammars (context-free grammar). 
\item Type-3 grammars (regular grammar).
\end{itemize}


\subsubsection{Context-Free Grammar}
Context-Free Grammar (CFG)
A context-free grammar is has four component
\begin{itemize}
\item [1.] A set of terminal symbols, sometimes referred to as ”tokens.” The
terminals are the elementary symbols of the language defined by the
grammar .
\item [2.] A set of non-terminals, sometimes called ”syntactic variables.” Each
non- terminal represents a set of strings of terminals, in a manner we
shall describe.
\item [3.] A set of productions, which are rules for replacing (or rewriting) non-
terminal symbols (on the left side of the production) in a string with
other non-terminal or terminal symbols (on the right side of the pro-
duction).
\item [4.] A start symbol, which is a special non-terminal symbol that appears in the initial string generated by the grammar.
\end{itemize}
\cite{aho1986compilers} it can be recognized by pushdown automaton.\\

Content-free grammar can represent the algebraic expressions.The table below specify a set o rules:

\begin{tabular}{|p{6cm}|p{6cm}|}
\hline \textbf{Rules} & \textbf{Description}\\ 
\hline  $1. S \rightarrow number $ & S produce a number, may be a integer or a float ,defined by regular expression  \\ 
\hline  $2.  S \rightarrow boolean $ &  produce a boolean value \\ 
\hline  $3. S \rightarrow string $&  produce a string value \\ 
\hline  $4.S \rightarrow S+S $&  adding of two S expression\\ 
\hline  $5.S \rightarrow S-S $ &  substrate of two S expression\\
\hline $6.S\rightarrow S \%S $ & mod of two S expression \\
\hline $7. S\rightarrow S > S $ &  logical greater  of two S expression\\
\hline $8.S \rightarrow S \&\& S $ & logical and of two S expression \\
\hline $9.S \rightarrow ( S) $ &  bracket of the S expression\\
\hline $10.S \rightarrow S == S $ & logical and of two S expression \\
\hline 
\end{tabular} 

This grammar can, for example, generate the string 
$$  ((a+2) == (a*2) )\&\& (a > 0)  $$

can be derived from the projection rules as follow,
 
\begin{tabular}{|l|l|}
\hline S & the start symbol\\ 
\hline S \&\& S & rule 8 \\ 
\hline  (S) \&\&S & rule 9\\ 
\hline   (S==S) \&\& S & rule 10 \\ 
\hline  ((S)==S)\&\& S  & rule  9\\ 
\hline ((S+S))==S)\&\& S & rule 4\\
\hline ((S+S))==S)\&\& (S) & rule 9 \\
\hline  ((S+S))==(S*S))\&\& (S$>$S) & rule 7\\
\hline ((a+S))==(S*S))\&\&(S$>$S)  & rule 3\\
\hline ((a+2))==(S*S))\&\&(S$>$S) & rule 1\\
\hline ((a+2))==(a*S))\&\&(S$>$S) & rule 3\\
\hline ((a+2))==(a*2))\&\&(S$>$S) & rule 1\\
\hline ((a+2))==(a*2))\&\&(a$>$S) & rule 3\\
\hline ((a+2))==(a*2))\&\&(a$>$0) & rule 1\\
\hline

\end{tabular} 
 
 


\subsection{Backus–Naur Form and Extended Backus–Naur Form}
The Backus-Naur Form(BNF) is a metalanguage to write  production rules that express the type-2 grammar (context-free grammar).It restricts the appearance of terminal and non-terminal in each side of the production equation.A canonical BNF production rule may look like :
 \[   <symbol> ::= \_\_expression\_\_ \]
 
The left side of the equation can only be non-terminal thus enclosed with $<>$ .The right side can be terminals and non-terminals,a vertical bar '|' is used to represent choice between terminals and non-terminals.\\

The  Extended Backus–Naur Form (EBNF) and extension upon the BNF.Three regular expression qualifiers are added to simplified some expressions,they are:
\begin{itemize}
\item ? : which means that the symbol (or group of symbols in parenthesis) to the left of the operator is
optional (it can appear zero or one times)
\item * : which means that something can be repeated any number of times (and possibly be skipped
altogether)
\item + : which means that something can appear one or more times 
\end{itemize} \cite{aho1986compilers}

Recursive rules of BNF like 
\[   1. <exp> := <exp> | sub \]
\[	 2. <exp> := sub     \]
 
that expressing a sequence of a particular syntactic elements can be simplified using quantifiers in EBNF to $ <exp>:=sub+ $



\section{Parser Generator Haskell Happy}
Happy is a parser generator system for Haskell, similar to the tool `yacc' for C. Like `yacc', it takes a file containing an annotated BNF specification of a grammar and produces a Haskell module containing a parser for the grammar.
\cite{happy}

By using its own EBNF like syntax,we could write a parser description.The happy parser generator is able to recognize and compile it into Haskell source code.


\section{Monadic Parsing using Parsec}
In the early stage of this project,parser is built using \textbf{ParseC},
Parsec is an industrial strength, monadic parser combinator library for Haskell. It can parse context-sensitive, infinite look-ahead grammars but it performs best on
predictive (LL\cite{aho1986compilers}) grammars. Combinator parsing is well known in the literature
and offers several advantages to YACC or event-based parsing. \cite{leijen2001parsec}

LL grammars have the distinctive properties that they are non-ambiguous and
not left-recursive. A grammar is LL(k) if the associated predictive parser needs
at most k tokens lookahead to disambiguate a parse tree.\cite{real_parsec}


Compared toe parser generator , monadic parsing has two major benifits
1. No need to learn additional parser generator grammar since parser combinator is written in the same language. 2.parser can be adjust easily .


\section{Lexical analysis}
Before parsing,the lexical analyser will scan the source code and generate a sequence of tokens.The tokens are often defined by regular expressions.

For example,the statement \textbf{s3 = s1 + "a string"} will be parse to tokens,

\begin{tabular}{|c|c|}
\hline s3 & identifier ,variable name \\ 
\hline = & operator \\ 
\hline s1 & identifier,variable name \\ 
\hline + & opeartor \\ 
\hline "a string" & a string constant \\ 
\hline 
\end{tabular} 

The regular expression $ [a-zA-Z]{1}[a-zA-Z\setminus\_0-9]*  $ can identify strings that begin will alphabetical character.


\subsection{The Lexer Generator Alex}
Alex is a tool for generating lexical analysers in Haskell, given a description of the tokens to be recognised in the form of regular expressions. It is similar to the tools lex and flex for C/C++.
\\\\
Alex takes a description of tokens based on regular expressions and generates a Haskell module containing code for scanning text efficiently. Alex is designed to be familiar to exisiting lex users, although it does depart from lex in a number of ways.\cite{alex}

\section{Testing and Evaluation Technologies}
There are two type of testing in Haskell.The type testing and unit testing.There correspond to two package in Haskell,QuickCheck and HUnit.
\subsection*{QucikCheck}
For pure functions programmer can write logical expression or functional specification to prove the code is correct ranter than provide a specify test case as an input of the function.
One of the example to test a function that takes the first five element of a list is using a length function $ if \;\forall \;s.\; length(take5 \;s) = 5 \;$ is true,then the $take5$ function is probably true.
The QuickCheck package allow us to write the assertion in Haskell code this way.
\begin{hcode}
quickCheck (\s -> length (take5 s) == 5)
\end{hcode}

\subsection*{HUnit}
HUnit is a unit testing framework for Haskell to test the impure code.it is similar to the JUnit tool for Java.In unit testing,it is required to provide an input and verify the output.\\
 Test specification in HUnit is even more concise and flexible than in JUnit, thanks to the nature of the Haskell language.  HUnit currently includes only a text-based test controller, but the framework is designed for easy extension. \cite{hunit}




